{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcLZlnzW5AyyhCh88HlqLo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arac22/keras-demo/blob/main/shower_discrete_ok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRuqIEWBirkg"
      },
      "outputs": [],
      "source": [
        "!pip install gym[box2d]\n",
        "!pip install stable_baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym"
      ],
      "metadata": {
        "id": "DfR4AwDTj1zX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "import random\n",
        "\n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box\n",
        "\n",
        "INITIAL_STATE = 3\n",
        "TARGET_STATE = 3\n",
        "TEMPERATURE_MIN = 0\n",
        "TEMPERATURE_MAX = 5\n",
        "\n",
        "SHOWER_LENGTH = 20\n",
        "\n",
        "\n",
        "class ShowerEnv(Env):\n",
        "\n",
        "    # limit temperature to obs range\n",
        "    def validate_state(self):\n",
        "        if self.state < int(self.observation_space.low):\n",
        "            self.state = int (self.observation_space.low)\n",
        "        elif self.state > int(self.observation_space.high):\n",
        "            self.state = int(self.observation_space.high)\n",
        "     \n",
        "    def __init__(self):\n",
        "        # Actions we can take, down, stay, up\n",
        "        self.action_space = Discrete(3)\n",
        "        # Temperature array\n",
        "        #self.observation_space = Box(low=np.array(TEMPERATURE_MIN), high=np.array(TEMPERATURE_MAX))\n",
        "        self.observation_space = Box(low=TEMPERATURE_MIN, high=TEMPERATURE_MAX, shape=(1,), dtype=np.int32)\n",
        "        # Set start temp\n",
        "        self.state = INITIAL_STATE + random.randint(-3,3)\n",
        "        self.validate_state()\n",
        "        # Set shower length\n",
        "        self.shower_length = SHOWER_LENGTH\n",
        "    \n",
        "\n",
        "        \n",
        "    def step(self, action):\n",
        "        # Apply action\n",
        "        # 0 -1 = -1 temperature\n",
        "        # 1 -1 = 0 \n",
        "        # 2 -1 = 1 temperature \n",
        "        self.state += action -1 \n",
        "\n",
        "        self.validate_state()\n",
        "\n",
        "        # Reduce shower length by 1 second\n",
        "        self.shower_length -= 1 \n",
        "        \n",
        "        # Calculate reward\n",
        "        if self.state == TARGET_STATE: \n",
        "            reward =1 \n",
        "        else: \n",
        "            reward = -1 \n",
        "        \n",
        "        # Check if shower is done\n",
        "        if self.shower_length <= 0: \n",
        "            done = True\n",
        "        else:\n",
        "            done = False\n",
        "        \n",
        "        # Apply temperature noise\n",
        "        # self.state += random.randint(-1,1)\n",
        "        # Set placeholder for info\n",
        "        info = {}\n",
        "        \n",
        "        # Return step information\n",
        "        return (self.state,), reward, done, info\n",
        "\n",
        "    def render(self):\n",
        "        # Implement viz\n",
        "        pass\n",
        "    \n",
        "    def reset(self):\n",
        "        # Reset shower temperature\n",
        "        # self.state = 38 + random.randint(-3,3)\n",
        "        self.state = INITIAL_STATE + random.randint(-3,3)\n",
        "        self.validate_state()\n",
        "        # Reset shower time\n",
        "        self.shower_length = SHOWER_LENGTH \n",
        "        return (self.state,)"
      ],
      "metadata": {
        "id": "R586UpODrZYZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = ShowerEnv()\n",
        "\n",
        "print(env.metadata)\n",
        "print('Action space:', env.action_space)\n",
        "print('Observation space:', env.observation_space)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF4m0uNPrdeu",
        "outputId": "ec28532c-3d1c-4110-b4f1-11db59c83c4e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'render.modes': []}\n",
            "Action space: Discrete(3)\n",
            "Observation space: Box([0], [5], (1,), int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "#model = A2C('MlpPolicy', env, verbose=1)\n",
        "model = PPO('MlpPolicy', env, verbose=1)\n",
        "model.learn(total_timesteps=100000)\n",
        "\n"
      ],
      "metadata": {
        "id": "z4F_ucw4uDEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "episodes = 10\n",
        "\n",
        "for ep in range(episodes):\n",
        "    ep_score = 0\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action, _states = model.predict(obs)\n",
        "        obs, rewards, done, info = env.step(action)\n",
        "        env.render()\n",
        "        # print(rewards)\n",
        "        ep_score += rewards \n",
        "    print(ep_score) "
      ],
      "metadata": {
        "id": "twfnjxYYpWXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save models\n",
        "\n",
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "import os\n",
        "\n",
        "\n",
        "models_dir = \"models/PPO\"\n",
        "log_dir = \"logs\"\n",
        "\n",
        "if not os.path.exists(models_dir):\n",
        "    os.makedirs(models_dir)\n",
        "\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "\n",
        "\n",
        "env = ShowerEnv() \n",
        "env.reset()\n",
        "\n",
        "model = PPO('MlpPolicy', env, verbose=1)\n",
        "\n",
        "TIMESTEPS = 1000\n",
        "iters = 0\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False)\n",
        "    model.save(f\"{models_dir}/{TIMESTEPS*iters}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXiaGpJorvKR",
        "outputId": "b9488921-ca7e-4e7e-c84c-e1fd3bf4f22d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 20       |\n",
            "|    ep_rew_mean     | -13.5    |\n",
            "| time/              |          |\n",
            "|    fps             | 1530     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 20       |\n",
            "|    ep_rew_mean     | -10.9    |\n",
            "| time/              |          |\n",
            "|    fps             | 1549     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 4096     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 20       |\n",
            "|    ep_rew_mean     | -7.74    |\n",
            "| time/              |          |\n",
            "|    fps             | 1522     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 6144     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 20       |\n",
            "|    ep_rew_mean     | -5.06    |\n",
            "| time/              |          |\n",
            "|    fps             | 1574     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 8192     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 20       |\n",
            "|    ep_rew_mean     | -0.62    |\n",
            "| time/              |          |\n",
            "|    fps             | 1559     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 10240    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 20       |\n",
            "|    ep_rew_mean     | 3.84     |\n",
            "| time/              |          |\n",
            "|    fps             | 1566     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 12288    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 20       |\n",
            "|    ep_rew_mean     | 8.32     |\n",
            "| time/              |          |\n",
            "|    fps             | 1558     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 14336    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 20       |\n",
            "|    ep_rew_mean     | 11.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 1553     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 16384    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 20       |\n",
            "|    ep_rew_mean     | 12.9     |\n",
            "| time/              |          |\n",
            "|    fps             | 1576     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 18432    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 20       |\n",
            "|    ep_rew_mean     | 13.8     |\n",
            "| time/              |          |\n",
            "|    fps             | 1564     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 20480    |\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOsDUniaup-6",
        "outputId": "3632bc47-b979-4768-ead7-a6129cbfec50"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-20 14:12:03.209083: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.9.1 at http://localhost:6006/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# laod model\n",
        "\n",
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "models_dir = \"models/PPO\"\n",
        "logdir = \"logs\"\n",
        "\n",
        "env = ShowerEnv()\n",
        "env.reset()\n",
        "\n",
        "model_path = f\"{models_dir}/60000.zip\"\n",
        "model = PPO.load(model_path, env=env)\n",
        "\n",
        "episodes = 5\n",
        "\n",
        "for ep in range(episodes):\n",
        "    ep_score = 0\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action, _states = model.predict(obs)\n",
        "        obs, rewards, done, info = env.step(action)\n",
        "        env.render()\n",
        "        # print(rewards)\n",
        "        ep_score += rewards \n",
        "    print(ep_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvtyU3QKspCQ",
        "outputId": "496298b1-1d6c-4219-a565-b387ad35a3e8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n"
          ]
        }
      ]
    }
  ]
}