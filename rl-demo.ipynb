{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Code\n\nhttps://github.com/nicknochnack/OpenAI-Reinforcement-Learning-with-Custom-Environment\n\nVideo\n\nhttps://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbk1Iang2ME0wODgzTlctRVl6LUdBRFU0WFloZ3xBQ3Jtc0tua2k5cFpNbzlNX2UxWmlzXzl5MzlZX3VPd0RoZ1Y3UVpEUjl5MWkweWs4TFM2MmpYWUdESEI0VmU2TndCVkJUaWFUUmZraVFGN3p5WWdyalRzOFhxcmdfU2tRSkwzdGlyMDN3eGFVRVh5RWhQWklicw&q=https%3A%2F%2Fgithub.com%2Fnicknochnack%2FOpenAI-Reinforcement-Learning-with-Custom-Environment&v=bD6V3rcr_54","metadata":{}},{"cell_type":"markdown","source":"# 0. Install Dependencies","metadata":{}},{"cell_type":"code","source":"# !pip install tensorflow\n#!pip install gym\n#!pip install keras\n!pip install keras-rl2","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:20:02.753692Z","iopub.execute_input":"2022-10-06T16:20:02.754129Z","iopub.status.idle":"2022-10-06T16:20:38.498755Z","shell.execute_reply.started":"2022-10-06T16:20:02.754098Z","shell.execute_reply":"2022-10-06T16:20:38.497085Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Collecting keras-rl2\n  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m657.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (from keras-rl2) (2.6.4)\nCollecting h5py~=3.1.0\n  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.1.0)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (0.2.0)\nRequirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (2.6.0)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.6.3)\nCollecting numpy~=1.19.2\n  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (5.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (3.19.4)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (0.15.0)\nRequirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.15.0)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.1.2)\nRequirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (0.4.0)\nRequirement already satisfied: keras<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (2.6.0)\nRequirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.43.0)\nCollecting typing-extensions<3.11,>=3.7\n  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\nCollecting tensorboard<2.7,>=2.6.0\n  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (0.37.1)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.12.1)\nRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.12)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-rl2) (3.3.0)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow->keras-rl2) (1.5.2)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (0.4.6)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (1.35.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (2.28.1)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (59.8.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (1.8.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (3.3.7)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (2.2.2)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (4.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (4.12.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (2022.6.15.2)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (1.26.12)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (2.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (3.8.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow->keras-rl2) (3.2.0)\nInstalling collected packages: typing-extensions, numpy, h5py, tensorboard, keras-rl2\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.3.0\n    Uninstalling typing_extensions-4.3.0:\n      Successfully uninstalled typing_extensions-4.3.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.21.6\n    Uninstalling numpy-1.21.6:\n      Successfully uninstalled numpy-1.21.6\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.7.0\n    Uninstalling h5py-3.7.0:\n      Successfully uninstalled h5py-3.7.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.10.0\n    Uninstalling tensorboard-2.10.0:\n      Successfully uninstalled tensorboard-2.10.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\nbeatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\nxarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\ntfx-bsl 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\npytorch-lightning 1.7.6 requires tensorboard>=2.9.1, but you have tensorboard 2.6.0 which is incompatible.\npytorch-lightning 1.7.6 requires typing-extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\npdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.3 which is incompatible.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\nnnabla 1.30.0 requires numpy>=1.20.0, but you have numpy 1.19.5 which is incompatible.\njax 0.3.17 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\nflax 0.6.0 requires rich~=11.1, but you have rich 12.1.0 which is incompatible.\nflax 0.6.0 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\nflake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.12.0 which is incompatible.\nfeaturetools 1.11.1 requires numpy>=1.21.0, but you have numpy 1.19.5 which is incompatible.\ncmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\napache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\napache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 8.0.0 which is incompatible.\nallennlp 2.10.0 requires h5py>=3.6.0, but you have h5py 3.1.0 which is incompatible.\nallennlp 2.10.0 requires numpy>=1.21.4, but you have numpy 1.19.5 which is incompatible.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\naioitertools 0.10.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\naiobotocore 2.4.0 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.27.72 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed h5py-3.1.0 keras-rl2-1.0.5 numpy-1.19.5 tensorboard-2.6.0 typing-extensions-3.10.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# 1. Test Random Environment with OpenAI Gym","metadata":{}},{"cell_type":"code","source":"from gym import Env\nfrom gym.spaces import Discrete, Box\nimport numpy as np\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:19:14.739143Z","iopub.execute_input":"2022-10-06T16:19:14.739709Z","iopub.status.idle":"2022-10-06T16:19:15.153529Z","shell.execute_reply.started":"2022-10-06T16:19:14.739572Z","shell.execute_reply":"2022-10-06T16:19:15.152561Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class ShowerEnv(Env):\n    def __init__(self):\n        # Actions we can take, down, stay, up\n        self.action_space = Discrete(3)\n        # Temperature array\n        self.observation_space = Box(low=np.array([0]), high=np.array([100]))\n        # Set start temp\n        self.state = 38 + random.randint(-3,3)\n        # Set shower length\n        self.shower_length = 60\n        \n    def step(self, action):\n        # Apply action\n        # 0 -1 = -1 temperature\n        # 1 -1 = 0 \n        # 2 -1 = 1 temperature \n        self.state += action -1 \n        # Reduce shower length by 1 second\n        self.shower_length -= 1 \n        \n        # Calculate reward\n        if self.state >=37 and self.state <=39: \n            reward =1 \n        else: \n            reward = -1 \n        \n        # Check if shower is done\n        if self.shower_length <= 0: \n            done = True\n        else:\n            done = False\n        \n        # Apply temperature noise\n        #self.state += random.randint(-1,1)\n        # Set placeholder for info\n        info = {}\n        \n        # Return step information\n        return self.state, reward, done, info\n\n    def render(self):\n        # Implement viz\n        pass\n    \n    def reset(self):\n        # Reset shower temperature\n        self.state = 38 + random.randint(-3,3)\n        # Reset shower time\n        self.shower_length = 60 \n        return self.state\n    ","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:19:16.961123Z","iopub.execute_input":"2022-10-06T16:19:16.962259Z","iopub.status.idle":"2022-10-06T16:19:16.972762Z","shell.execute_reply.started":"2022-10-06T16:19:16.962214Z","shell.execute_reply":"2022-10-06T16:19:16.971405Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"env = ShowerEnv()","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:19:19.610291Z","iopub.execute_input":"2022-10-06T16:19:19.611159Z","iopub.status.idle":"2022-10-06T16:19:19.620233Z","shell.execute_reply.started":"2022-10-06T16:19:19.611119Z","shell.execute_reply":"2022-10-06T16:19:19.618990Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"env.observation_space.sample()","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:19:21.476157Z","iopub.execute_input":"2022-10-06T16:19:21.476586Z","iopub.status.idle":"2022-10-06T16:19:21.488356Z","shell.execute_reply.started":"2022-10-06T16:19:21.476551Z","shell.execute_reply":"2022-10-06T16:19:21.487166Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array([12.060718], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"episodes = 10\nfor episode in range(1, episodes+1):\n    state = env.reset()\n    done = False\n    score = 0 \n    \n    while not done:\n        # env.render(mode=\"ipython\")\n        action = env.action_space.sample()\n        n_state, reward, done, info = env.step(action)\n        score+=reward\n    print('Episode:{} Score:{}'.format(episode, score))","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:19:23.415826Z","iopub.execute_input":"2022-10-06T16:19:23.416287Z","iopub.status.idle":"2022-10-06T16:19:23.429697Z","shell.execute_reply.started":"2022-10-06T16:19:23.416253Z","shell.execute_reply":"2022-10-06T16:19:23.428205Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Episode:1 Score:-22\nEpisode:2 Score:-16\nEpisode:3 Score:-22\nEpisode:4 Score:-4\nEpisode:5 Score:-36\nEpisode:6 Score:-38\nEpisode:7 Score:-38\nEpisode:8 Score:-26\nEpisode:9 Score:-58\nEpisode:10 Score:-52\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. Create a Deep Learning Model with Keras","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow.keras as keras\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.optimizers import adam_v2","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:25:00.190738Z","iopub.execute_input":"2022-10-06T16:25:00.191232Z","iopub.status.idle":"2022-10-06T16:25:00.198525Z","shell.execute_reply.started":"2022-10-06T16:25:00.191195Z","shell.execute_reply":"2022-10-06T16:25:00.196745Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"states = env.observation_space.shape\nactions = env.action_space.n","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:22:33.419880Z","iopub.execute_input":"2022-10-06T16:22:33.420341Z","iopub.status.idle":"2022-10-06T16:22:33.426269Z","shell.execute_reply.started":"2022-10-06T16:22:33.420307Z","shell.execute_reply":"2022-10-06T16:22:33.425012Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"states","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:22:34.843170Z","iopub.execute_input":"2022-10-06T16:22:34.844046Z","iopub.status.idle":"2022-10-06T16:22:34.852834Z","shell.execute_reply.started":"2022-10-06T16:22:34.843992Z","shell.execute_reply":"2022-10-06T16:22:34.851507Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(1,)"},"metadata":{}}]},{"cell_type":"code","source":"def build_model(states, actions):\n    model = Sequential()    \n    model.add(Dense(24, activation='relu', input_shape=states))\n    model.add(Dense(24, activation='relu'))\n    model.add(Dense(actions, activation='linear'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:22:36.020876Z","iopub.execute_input":"2022-10-06T16:22:36.022046Z","iopub.status.idle":"2022-10-06T16:22:36.029096Z","shell.execute_reply.started":"2022-10-06T16:22:36.021999Z","shell.execute_reply":"2022-10-06T16:22:36.027762Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# del model ","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:22:37.173274Z","iopub.execute_input":"2022-10-06T16:22:37.174043Z","iopub.status.idle":"2022-10-06T16:22:37.179059Z","shell.execute_reply.started":"2022-10-06T16:22:37.173999Z","shell.execute_reply":"2022-10-06T16:22:37.177801Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = build_model(states, actions)","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:22:38.338861Z","iopub.execute_input":"2022-10-06T16:22:38.340032Z","iopub.status.idle":"2022-10-06T16:22:38.400976Z","shell.execute_reply.started":"2022-10-06T16:22:38.339988Z","shell.execute_reply":"2022-10-06T16:22:38.400055Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:22:39.971666Z","iopub.execute_input":"2022-10-06T16:22:39.972172Z","iopub.status.idle":"2022-10-06T16:22:39.979211Z","shell.execute_reply.started":"2022-10-06T16:22:39.972125Z","shell.execute_reply":"2022-10-06T16:22:39.977888Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 24)                48        \n_________________________________________________________________\ndense_4 (Dense)              (None, 24)                600       \n_________________________________________________________________\ndense_5 (Dense)              (None, 3)                 75        \n=================================================================\nTotal params: 723\nTrainable params: 723\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3. Build Agent with Keras-RL","metadata":{}},{"cell_type":"code","source":"from rl.agents import DQNAgent\nfrom rl.policy import BoltzmannQPolicy\nfrom rl.memory import SequentialMemory","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:22:43.295432Z","iopub.execute_input":"2022-10-06T16:22:43.296919Z","iopub.status.idle":"2022-10-06T16:22:43.303963Z","shell.execute_reply.started":"2022-10-06T16:22:43.296846Z","shell.execute_reply":"2022-10-06T16:22:43.302531Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def build_agent(model, actions):\n    policy = BoltzmannQPolicy()\n    memory = SequentialMemory(limit=50000, window_length=1)\n    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n    return dqn","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:22:44.844528Z","iopub.execute_input":"2022-10-06T16:22:44.844996Z","iopub.status.idle":"2022-10-06T16:22:44.851694Z","shell.execute_reply.started":"2022-10-06T16:22:44.844961Z","shell.execute_reply":"2022-10-06T16:22:44.850379Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"dqn = build_agent(model, actions)","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:25:09.371144Z","iopub.execute_input":"2022-10-06T16:25:09.371566Z","iopub.status.idle":"2022-10-06T16:25:09.377637Z","shell.execute_reply.started":"2022-10-06T16:25:09.371530Z","shell.execute_reply":"2022-10-06T16:25:09.376226Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"dqn.compile(adam_v2.Adam(learning_rate=1e-3), metrics=['mae'])","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:25:12.072172Z","iopub.execute_input":"2022-10-06T16:25:12.072598Z","iopub.status.idle":"2022-10-06T16:25:12.943744Z","shell.execute_reply.started":"2022-10-06T16:25:12.072563Z","shell.execute_reply":"2022-10-06T16:25:12.942359Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"2022-10-06 16:25:12.130564: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"}]},{"cell_type":"code","source":"dqn.fit(env, nb_steps=5000, visualize=False, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:25:19.769875Z","iopub.execute_input":"2022-10-06T16:25:19.770324Z","iopub.status.idle":"2022-10-06T16:26:07.098765Z","shell.execute_reply.started":"2022-10-06T16:25:19.770274Z","shell.execute_reply":"2022-10-06T16:26:07.097852Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Training for 5000 steps ...\nInterval 1 (0 steps performed)\n    1/10000 [..............................] - ETA: 25:14 - reward: -1.0000","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  warnings.warn('`Model.state_updates` will be removed in a future version. '\n/opt/conda/lib/python3.7/site-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n","output_type":"stream"},{"name":"stdout","text":" 4998/10000 [=============>................] - ETA: 47s - reward: -0.4094done, took 47.318 seconds\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f54b9d78390>"},"metadata":{}}]},{"cell_type":"code","source":"scores = dqn.test(env, nb_episodes=100, visualize=False)\nprint(np.mean(scores.history['episode_reward']))","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:26:24.937735Z","iopub.execute_input":"2022-10-06T16:26:24.938131Z","iopub.status.idle":"2022-10-06T16:26:30.460128Z","shell.execute_reply.started":"2022-10-06T16:26:24.938099Z","shell.execute_reply":"2022-10-06T16:26:30.458602Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Testing for 100 episodes ...\nEpisode 1: reward: 60.000, steps: 60\nEpisode 2: reward: -60.000, steps: 60\nEpisode 3: reward: 60.000, steps: 60\nEpisode 4: reward: -60.000, steps: 60\nEpisode 5: reward: -60.000, steps: 60\nEpisode 6: reward: -60.000, steps: 60\nEpisode 7: reward: 60.000, steps: 60\nEpisode 8: reward: -60.000, steps: 60\nEpisode 9: reward: 60.000, steps: 60\nEpisode 10: reward: -60.000, steps: 60\nEpisode 11: reward: -60.000, steps: 60\nEpisode 12: reward: 60.000, steps: 60\nEpisode 13: reward: -60.000, steps: 60\nEpisode 14: reward: -60.000, steps: 60\nEpisode 15: reward: -60.000, steps: 60\nEpisode 16: reward: -60.000, steps: 60\nEpisode 17: reward: 60.000, steps: 60\nEpisode 18: reward: -60.000, steps: 60\nEpisode 19: reward: 60.000, steps: 60\nEpisode 20: reward: -60.000, steps: 60\nEpisode 21: reward: -60.000, steps: 60\nEpisode 22: reward: -60.000, steps: 60\nEpisode 23: reward: -60.000, steps: 60\nEpisode 24: reward: 60.000, steps: 60\nEpisode 25: reward: -60.000, steps: 60\nEpisode 26: reward: -60.000, steps: 60\nEpisode 27: reward: -60.000, steps: 60\nEpisode 28: reward: 60.000, steps: 60\nEpisode 29: reward: 60.000, steps: 60\nEpisode 30: reward: -60.000, steps: 60\nEpisode 31: reward: 60.000, steps: 60\nEpisode 32: reward: -60.000, steps: 60\nEpisode 33: reward: 60.000, steps: 60\nEpisode 34: reward: 60.000, steps: 60\nEpisode 35: reward: 60.000, steps: 60\nEpisode 36: reward: -60.000, steps: 60\nEpisode 37: reward: -60.000, steps: 60\nEpisode 38: reward: 60.000, steps: 60\nEpisode 39: reward: -60.000, steps: 60\nEpisode 40: reward: -60.000, steps: 60\nEpisode 41: reward: -60.000, steps: 60\nEpisode 42: reward: 60.000, steps: 60\nEpisode 43: reward: -60.000, steps: 60\nEpisode 44: reward: 60.000, steps: 60\nEpisode 45: reward: 60.000, steps: 60\nEpisode 46: reward: -60.000, steps: 60\nEpisode 47: reward: 60.000, steps: 60\nEpisode 48: reward: -60.000, steps: 60\nEpisode 49: reward: 60.000, steps: 60\nEpisode 50: reward: 60.000, steps: 60\nEpisode 51: reward: -60.000, steps: 60\nEpisode 52: reward: 60.000, steps: 60\nEpisode 53: reward: 60.000, steps: 60\nEpisode 54: reward: -60.000, steps: 60\nEpisode 55: reward: 60.000, steps: 60\nEpisode 56: reward: -60.000, steps: 60\nEpisode 57: reward: -60.000, steps: 60\nEpisode 58: reward: -60.000, steps: 60\nEpisode 59: reward: -60.000, steps: 60\nEpisode 60: reward: 60.000, steps: 60\nEpisode 61: reward: 60.000, steps: 60\nEpisode 62: reward: -60.000, steps: 60\nEpisode 63: reward: 60.000, steps: 60\nEpisode 64: reward: 60.000, steps: 60\nEpisode 65: reward: 60.000, steps: 60\nEpisode 66: reward: -60.000, steps: 60\nEpisode 67: reward: -60.000, steps: 60\nEpisode 68: reward: 60.000, steps: 60\nEpisode 69: reward: 60.000, steps: 60\nEpisode 70: reward: -60.000, steps: 60\nEpisode 71: reward: 60.000, steps: 60\nEpisode 72: reward: -60.000, steps: 60\nEpisode 73: reward: 60.000, steps: 60\nEpisode 74: reward: 60.000, steps: 60\nEpisode 75: reward: -60.000, steps: 60\nEpisode 76: reward: 60.000, steps: 60\nEpisode 77: reward: -60.000, steps: 60\nEpisode 78: reward: -60.000, steps: 60\nEpisode 79: reward: -60.000, steps: 60\nEpisode 80: reward: 60.000, steps: 60\nEpisode 81: reward: -60.000, steps: 60\nEpisode 82: reward: -60.000, steps: 60\nEpisode 83: reward: -60.000, steps: 60\nEpisode 84: reward: -60.000, steps: 60\nEpisode 85: reward: -60.000, steps: 60\nEpisode 86: reward: 60.000, steps: 60\nEpisode 87: reward: -60.000, steps: 60\nEpisode 88: reward: -60.000, steps: 60\nEpisode 89: reward: 60.000, steps: 60\nEpisode 90: reward: -60.000, steps: 60\nEpisode 91: reward: -60.000, steps: 60\nEpisode 92: reward: -60.000, steps: 60\nEpisode 93: reward: -60.000, steps: 60\nEpisode 94: reward: -60.000, steps: 60\nEpisode 95: reward: 60.000, steps: 60\nEpisode 96: reward: -60.000, steps: 60\nEpisode 97: reward: 60.000, steps: 60\nEpisode 98: reward: 60.000, steps: 60\nEpisode 99: reward: 60.000, steps: 60\nEpisode 100: reward: 60.000, steps: 60\n-8.4\n","output_type":"stream"}]},{"cell_type":"code","source":"_ = dqn.test(env, nb_episodes=15, visualize=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:26:36.304583Z","iopub.execute_input":"2022-10-06T16:26:36.305555Z","iopub.status.idle":"2022-10-06T16:26:37.093233Z","shell.execute_reply.started":"2022-10-06T16:26:36.305503Z","shell.execute_reply":"2022-10-06T16:26:37.091935Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Testing for 15 episodes ...\nEpisode 1: reward: -60.000, steps: 60\nEpisode 2: reward: -60.000, steps: 60\nEpisode 3: reward: -60.000, steps: 60\nEpisode 4: reward: 60.000, steps: 60\nEpisode 5: reward: 60.000, steps: 60\nEpisode 6: reward: -60.000, steps: 60\nEpisode 7: reward: -60.000, steps: 60\nEpisode 8: reward: 60.000, steps: 60\nEpisode 9: reward: 60.000, steps: 60\nEpisode 10: reward: 60.000, steps: 60\nEpisode 11: reward: -60.000, steps: 60\nEpisode 12: reward: 60.000, steps: 60\nEpisode 13: reward: 60.000, steps: 60\nEpisode 14: reward: 60.000, steps: 60\nEpisode 15: reward: -60.000, steps: 60\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 4. Reloading Agent from Memory","metadata":{}},{"cell_type":"code","source":"dqn.save_weights('dqn_weights.h5f', overwrite=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:26:45.814349Z","iopub.execute_input":"2022-10-06T16:26:45.814805Z","iopub.status.idle":"2022-10-06T16:26:45.899896Z","shell.execute_reply.started":"2022-10-06T16:26:45.814770Z","shell.execute_reply":"2022-10-06T16:26:45.898972Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"del model\ndel dqn\ndel env","metadata":{"execution":{"iopub.status.busy":"2022-10-06T15:24:16.352129Z","iopub.status.idle":"2022-10-06T15:24:16.353105Z","shell.execute_reply.started":"2022-10-06T15:24:16.352789Z","shell.execute_reply":"2022-10-06T15:24:16.352818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# env = gym.make('CartPole-v0')\nenv = ShowerEnv()\nactions = env.action_space.n\nstates = env.observation_space.shape\nmodel = build_model(states, actions)\ndqn = build_agent(model, actions)\ndqn.compile(adam_v2.Adam(learning_rate=1e-3), metrics=['mae'])","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:28:01.131845Z","iopub.execute_input":"2022-10-06T16:28:01.132272Z","iopub.status.idle":"2022-10-06T16:28:01.656800Z","shell.execute_reply.started":"2022-10-06T16:28:01.132232Z","shell.execute_reply":"2022-10-06T16:28:01.655168Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"dqn.load_weights('dqn_weights.h5f')","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:28:09.603330Z","iopub.execute_input":"2022-10-06T16:28:09.603827Z","iopub.status.idle":"2022-10-06T16:28:09.737410Z","shell.execute_reply.started":"2022-10-06T16:28:09.603789Z","shell.execute_reply":"2022-10-06T16:28:09.736126Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"_ = dqn.test(env, nb_episodes=5, visualize=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-06T16:28:19.975686Z","iopub.execute_input":"2022-10-06T16:28:19.976142Z","iopub.status.idle":"2022-10-06T16:28:20.274492Z","shell.execute_reply.started":"2022-10-06T16:28:19.976109Z","shell.execute_reply":"2022-10-06T16:28:20.272399Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Testing for 5 episodes ...\nEpisode 1: reward: -60.000, steps: 60\nEpisode 2: reward: 60.000, steps: 60\nEpisode 3: reward: -60.000, steps: 60\nEpisode 4: reward: -60.000, steps: 60\nEpisode 5: reward: 60.000, steps: 60\n","output_type":"stream"}]}]}